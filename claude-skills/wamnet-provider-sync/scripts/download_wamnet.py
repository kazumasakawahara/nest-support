#!/usr/bin/env python3
"""
WAM NETã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ˜ãƒ«ãƒ‘ãƒ¼

WAM NETã‹ã‚‰ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹éš›ã®æ¡ˆå†…ã¨ã€
ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç®¡ç†ã‚’è¡Œã„ã¾ã™ã€‚

â€» WAM NETã¯ãƒ­ã‚°ã‚¤ãƒ³ä¸è¦ã§ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ãŒã€
   è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„ãŸã‚ã€æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æ¡ˆå†…ã—ã¾ã™ã€‚
"""

import argparse
import json
import os
import shutil
import sys
from datetime import datetime
from pathlib import Path


# WAM NETã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã®URLï¼ˆæ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
WAMNET_OPENDATA_URL = "https://www.wam.go.jp/wamappl/shogaiservice_opendata.html"

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
DATA_DIR = Path(__file__).parent.parent / "data"
CURRENT_DIR = DATA_DIR / "current"
ARCHIVE_DIR = DATA_DIR / "archive"


def setup_directories():
    """ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    CURRENT_DIR.mkdir(parents=True, exist_ok=True)
    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™ã—ã¾ã—ãŸ:")
    print(f"   ç¾åœ¨ãƒ‡ãƒ¼ã‚¿: {CURRENT_DIR}")
    print(f"   ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: {ARCHIVE_DIR}")


def show_download_instructions(prefecture_code: str = "40"):
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †ã‚’è¡¨ç¤º"""
    config_path = Path(__file__).parent.parent / "config" / "prefectures.json"
    
    prefecture_name = "ç¦å²¡çœŒ"
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
            prefecture_name = config.get("prefectures", {}).get(prefecture_code, prefecture_name)
    
    print("\n" + "=" * 60)
    print("WAM NETã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †")
    print("=" * 60)
    print(f"""
1. ä»¥ä¸‹ã®URLã«ã‚¢ã‚¯ã‚»ã‚¹:
   {WAMNET_OPENDATA_URL}

2. ã€Œéšœå®³ç¦ç¥‰ã‚µãƒ¼ãƒ“ã‚¹ç­‰æƒ…å ±ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™

3. éƒ½é“åºœçœŒã‚’é¸æŠ: {prefecture_name}ï¼ˆã‚³ãƒ¼ãƒ‰: {prefecture_code}ï¼‰

4. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   - ãƒ•ã‚¡ã‚¤ãƒ«åä¾‹: shogai_fukuoka_YYYYMM.csv

5. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä»¥ä¸‹ã«é…ç½®:
   {CURRENT_DIR}/

6. åŒæœŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ:
   python sync_providers.py --csv-file {CURRENT_DIR}/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«.csv

â€» WAM NETã®ãƒ‡ãƒ¼ã‚¿ã¯å¹´2å›ï¼ˆ4æœˆãƒ»10æœˆé ƒï¼‰æ›´æ–°ã•ã‚Œã¾ã™
""")
    print("=" * 60 + "\n")


def archive_current(description: str = ""):
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
    archived_files = []
    for file in CURRENT_DIR.glob("*.csv"):
        archive_name = f"{file.stem}_{timestamp}{file.suffix}"
        archive_path = ARCHIVE_DIR / archive_name
        shutil.copy2(file, archive_path)
        archived_files.append(archive_name)
    
    if archived_files:
        print(f"âœ… {len(archived_files)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã—ãŸ:")
        for f in archived_files:
            print(f"   - {f}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        meta = {
            "archived_at": timestamp,
            "description": description,
            "files": archived_files
        }
        meta_path = ARCHIVE_DIR / f"archive_{timestamp}.json"
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
    else:
        print("â„¹ï¸ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")


def list_archives():
    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§ã‚’è¡¨ç¤º"""
    print("\nğŸ“ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§:\n")
    
    meta_files = sorted(ARCHIVE_DIR.glob("archive_*.json"), reverse=True)
    
    if not meta_files:
        print("  ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    for meta_path in meta_files[:10]:  # æœ€æ–°10ä»¶
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
        
        print(f"  ğŸ“… {meta.get('archived_at', 'unknown')}")
        if meta.get("description"):
            print(f"     {meta['description']}")
        for file in meta.get("files", []):
            print(f"     - {file}")
        print()


def list_current():
    """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    print("\nğŸ“‚ ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:\n")
    
    csv_files = list(CURRENT_DIR.glob("*.csv"))
    
    if not csv_files:
        print("  ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        print("  â†’ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †ã‚’ç¢ºèª: python download_wamnet.py --instructions")
        return
    
    for file in csv_files:
        stat = file.stat()
        size_kb = stat.st_size / 1024
        mtime = datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")
        print(f"  - {file.name}")
        print(f"    ã‚µã‚¤ã‚º: {size_kb:.1f}KB, æ›´æ–°: {mtime}")
    print()


def import_file(file_path: str, description: str = ""):
    """å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’currentã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    src = Path(file_path)
    if not src.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return False
    
    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
    archive_current(f"Importå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {description}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    dst = CURRENT_DIR / src.name
    shutil.copy2(src, dst)
    print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ: {dst}")
    return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="WAM NETã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ˜ãƒ«ãƒ‘ãƒ¼"
    )
    subparsers = parser.add_subparsers(dest="command", help="ã‚³ãƒãƒ³ãƒ‰")
    
    # setup
    setup_parser = subparsers.add_parser("setup", help="ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ")
    
    # instructions
    inst_parser = subparsers.add_parser("instructions", help="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †ã‚’è¡¨ç¤º")
    inst_parser.add_argument(
        "--prefecture", "-p",
        default="40",
        help="éƒ½é“åºœçœŒã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 40=ç¦å²¡çœŒï¼‰"
    )
    
    # archive
    arch_parser = subparsers.add_parser("archive", help="ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
    arch_parser.add_argument(
        "--description", "-d",
        default="",
        help="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã®èª¬æ˜"
    )
    
    # list
    list_parser = subparsers.add_parser("list", help="ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º")
    list_parser.add_argument(
        "--archives", "-a",
        action="store_true",
        help="ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§ã‚’è¡¨ç¤º"
    )
    
    # import
    import_parser = subparsers.add_parser("import", help="å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    import_parser.add_argument(
        "file",
        help="ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"
    )
    import_parser.add_argument(
        "--description", "-d",
        default="",
        help="ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®èª¬æ˜"
    )
    
    args = parser.parse_args()
    
    if args.command == "setup":
        setup_directories()
    elif args.command == "instructions":
        show_download_instructions(args.prefecture)
    elif args.command == "archive":
        setup_directories()
        archive_current(args.description)
    elif args.command == "list":
        setup_directories()
        if args.archives:
            list_archives()
        else:
            list_current()
    elif args.command == "import":
        setup_directories()
        import_file(args.file, args.description)
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ‰‹é †ã‚’è¡¨ç¤º
        show_download_instructions()


if __name__ == "__main__":
    main()
